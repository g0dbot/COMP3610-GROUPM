{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the libraries required by this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/g0dbot/.local/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (3.0.5)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (24.3.7)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: dm-tree in /home/g0dbot/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.1.8)\n",
      "Requirement already satisfied: rich in /home/g0dbot/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/g0dbot/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-hub in /home/g0dbot/.local/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow-hub) (4.25.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow-hub) (1.26.4)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow-hub) (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /home/g0dbot/.local/lib/python3.10/site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.16.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.0.5)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: packaging in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (23.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.62.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (24.3.7)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.3.2)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.25.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (59.6.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.16.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (4.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.37.1)\n",
      "Requirement already satisfied: dm-tree in /home/g0dbot/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.1.8)\n",
      "Requirement already satisfied: rich in /home/g0dbot/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/g0dbot/.local/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.0.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/g0dbot/.local/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/g0dbot/.local/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /home/g0dbot/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tuner in /home/g0dbot/.local/lib/python3.10/site-packages (1.4.7)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from keras-tuner) (2.25.1)\n",
      "Requirement already satisfied: keras in /home/g0dbot/.local/lib/python3.10/site-packages (from keras-tuner) (3.0.5)\n",
      "Requirement already satisfied: packaging in /home/g0dbot/.local/lib/python3.10/site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: kt-legacy in /home/g0dbot/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: numpy in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: absl-py in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: namex in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: rich in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: dm-tree in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: h5py in /home/g0dbot/.local/lib/python3.10/site-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from rich->keras->keras-tuner) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/g0dbot/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/g0dbot/.local/lib/python3.10/site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/g0dbot/.local/lib/python3.10/site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/g0dbot/.local/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/g0dbot/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/g0dbot/.local/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/g0dbot/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow-hub\n",
    "!pip install scikit-learn\n",
    "!pip install keras-tuner\n",
    "!pip install seaborn \n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was noted that some of the folders, in particular the art style ukiyo e had different names for the folders across the Latend Diffusion, Stable DIffusion and Human Samples. Considerations we made and the folders were renamed \"ukiyo-e\" across the test and train samples to help with the functions created to auto train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a reference to the base location of all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset\n"
     ]
    }
   ],
   "source": [
    "import os #used in this instance to get the relative location of the notebook\n",
    "\n",
    "#set the base directory NB windows using relative paths causes errors\n",
    "BASE_LOC = os.getcwd();\n",
    "print(BASE_LOC)#ensure current directory is not relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to return a file list from a particular directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def generate_image_df(directory, label, sample_size=None):\n",
    "    data = {'filepath': [], 'label': []}\n",
    "\n",
    "    #collect file paths and labels\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        data['filepath'].append(filepath)\n",
    "        data['label'].append(label)\n",
    "\n",
    "    #if we give a specified # of samples to use\n",
    "    if sample_size is not None:\n",
    "        if sample_size >= len(data['filepath']):\n",
    "            return pd.DataFrame(data)  #return all if sample_size is greater or equal to the number of files\n",
    "        else:\n",
    "            indices = random.sample(range(len(data['filepath'])), sample_size)\n",
    "            sampled_data = {key: [data[key][i] for i in indices] for key in data}\n",
    "            return pd.DataFrame(sampled_data)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to prepare a dataset based on the above function returning a list for each of the particular generation styles of a singe art style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artstyle_dataset(train_or_test, art_style, sample_size):\n",
    "    file_location = os.path.join(BASE_LOC, 'train')\n",
    "\n",
    "    if train_or_test == 'test':\n",
    "        file_location = os.path.join(BASE_LOC, 'test')\n",
    "\n",
    "    # half the sample size for each AI style\n",
    "    ai_hum_samp = sample_size // 2\n",
    "\n",
    "    # get human samples\n",
    "    human_location = os.path.join(file_location, art_style)\n",
    "    print(\"Location of human samples:\", human_location)\n",
    "    human_data = generate_image_df(human_location, \"HU\", sample_size)\n",
    "\n",
    "    ai_sd_location = os.path.join(file_location, 'AI_SD_' + art_style)\n",
    "    print(\"Location of ai_sd samples:\", ai_sd_location)\n",
    "    ai_sd_data = generate_image_df(ai_sd_location, 'AI', ai_hum_samp)\n",
    "\n",
    "    ai_ld_location = os.path.join(file_location, 'AI_SD_' + art_style)\n",
    "    print(\"Location of ai_ld samples:\", ai_ld_location)\n",
    "    ai_ld_data = generate_image_df(ai_ld_location, 'AI', ai_hum_samp)\n",
    "\n",
    "    # Combine human and AI data\n",
    "    dataset = pd.concat([human_data, ai_sd_data, ai_ld_data], ignore_index=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the genertae_image_df function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/ukiyo-e\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_ukiyo-e\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_ukiyo-e\n",
      "\n",
      "LABEL COUNTS ON ukiyoe_tr_1_10 TRAINING SET\n",
      "label\n",
      "HU    500\n",
      "AI    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ukiyoe_tr_1_10 = artstyle_dataset('train', 'ukiyo-e', 500)\n",
    "ukiyoe_1_10_file_counts = ukiyoe_tr_1_10['label'].value_counts()\n",
    "#print value count\n",
    "print(f\"\\nLABEL COUNTS ON ukiyoe_tr_1_10 TRAINING SET\")\n",
    "print(ukiyoe_1_10_file_counts)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearing the variables to clear memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ukiyoe_tr_1_10\n",
    "del ukiyoe_1_10_file_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 01:08:06.509160: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-19 01:08:08.238890: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-19 01:08:11.468445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 01:08:19.378624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def CNN_artystyle(filters=64, kernel_size=3, input_shape=(240, 240, 3), dense_units=64, output_units=2, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=input_shape))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(filters=filters, kernel_size=kernel_size, activation=activation))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=dense_units, activation=activation))\n",
    "    model.add(Dropout(0.5))  # Add dropout layer to reduce overfitting\n",
    "    model.add(Dense(units=output_units, activation='sigmoid'))\n",
    "    \n",
    "    # Configure early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    return model, early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def CNN_img_TRAIN_MODEL(model, training_dataset, validation_dataset, model_checkpoint, early_stopping, epochs=13):\n",
    "    #init training time\n",
    "    total_training_time = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #fit the model for the specified number of epochs\n",
    "    history = model.fit(training_dataset, epochs=epochs, validation_data=validation_dataset, callbacks=[model_checkpoint, early_stopping])\n",
    "\n",
    "    #calculate training time for the current batch of epochs\n",
    "    training_time = time.time() - start_time\n",
    "    total_training_time += training_time\n",
    "\n",
    "    #print total training time\n",
    "    print(\"Total training time so far: {:.2f} seconds\".format(total_training_time))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def CNN_train_artstyle(artstyle, sample_size=None, validation_split=0.2):\n",
    "    #creating the training set\n",
    "    init_dataset = artstyle_dataset('train', artstyle, sample_size)\n",
    "    init_dataset_counts = init_dataset['label'].value_counts()\n",
    "    #print value count\n",
    "    print(f\"\\nLABEL COUNTS ON {artstyle} TRAINING SET\")\n",
    "    print(init_dataset_counts)\n",
    "    print('\\n')\n",
    "\n",
    "    #splitting the init dataset into train and validation\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train, vali = train_test_split(init_dataset, test_size=validation_split, random_state=42)\n",
    "\n",
    "    #preprocess training set\n",
    "    train_dataset_gen = ImageDataGenerator(\n",
    "        rescale=1./255,   # to normalize pixel value\n",
    "        #rotation_range=7, # it will apply rotations to the image\n",
    "        #horizontal_flip=True, # it will flip image horizontally\n",
    "        #zoom_range=0.2  # it will increase and decrease zoom by 0.2x\n",
    "    )\n",
    "\n",
    "    train_dataset = train_dataset_gen.flow_from_dataframe(\n",
    "        dataframe=train,\n",
    "        x_col='filepath',  # Column containing file paths\n",
    "        y_col='label',     # Column containing labels\n",
    "        target_size=(240, 240),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',  \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print (train_dataset.class_indices)\n",
    "\n",
    "    #preprocess training set\n",
    "    vali_dataset_gen = ImageDataGenerator(\n",
    "        rescale=1./255,   # to normalize pixel value\n",
    "        rotation_range=7, # it will apply rotations to the image\n",
    "        horizontal_flip=True, # it will flip image horizontally\n",
    "        zoom_range=0.2  # it will increase and decrease zoom by 0.2x\n",
    "    )\n",
    "\n",
    "    vali_dataset = vali_dataset_gen.flow_from_dataframe(\n",
    "        dataframe=vali,\n",
    "        x_col='filepath',  # Column containing file paths\n",
    "        y_col='label',     # Column containing labels\n",
    "        target_size=(240, 240),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',  \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print (vali_dataset.class_indices)\n",
    "\n",
    "    #create the model\n",
    "    CNN_model, CNN_model_ES = CNN_artystyle()\n",
    "\n",
    "    #create checkpoint\n",
    "    os.makedirs('models_checkpoints', exist_ok=True)\n",
    "    model_file_name = f'CNN_{artstyle}'\n",
    "    \n",
    "    #create location for check point\n",
    "    current_dir = os.getcwd()\n",
    "    filename = (f'models_checkpoints/{model_file_name}.keras')\n",
    "    checkpoint_filepath = os.path.join(current_dir, filename)\n",
    "\n",
    "    #create a checkpoint\n",
    "    CNN_model_CheckPoint = ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "    #compile the model\n",
    "    # Compile the model\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = Adam()\n",
    "    CNN_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    #train the model\n",
    "    model_history = CNN_img_TRAIN_MODEL(CNN_model, train_dataset, vali_dataset, CNN_model_CheckPoint, CNN_model_ES)\n",
    "\n",
    "    #save model after training\n",
    "    os.makedirs('models_trained', exist_ok=True)\n",
    "    CNN_model.save(f'models_trained/{model_file_name}.keras')\n",
    "\n",
    "    return model_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save history as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def save_training_history(history, filename):\n",
    "    # Convert non-serializable parts to serializable format\n",
    "    serializable_history = {}\n",
    "    for key, value in history.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            serializable_history[key] = value.tolist()\n",
    "        else:\n",
    "            serializable_history[key] = value\n",
    "\n",
    "    directory_path = 'models_history'\n",
    "    curr_dir = os.getcwd()\n",
    "    full_dir_path = os.path.join(curr_dir, directory_path)\n",
    "\n",
    "    if not os.path.exists(full_dir_path):\n",
    "        os.makedirs(full_dir_path)\n",
    "\n",
    "    file_path = os.path.join(full_dir_path, filename)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(serializable_history, file)\n",
    "    \n",
    "    print('Training history saved to', file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/ukiyo-e\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_ukiyo-e\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_ukiyo-e\n",
      "\n",
      "LABEL COUNTS ON ukiyo-e TRAINING SET\n",
      "label\n",
      "HU    4500\n",
      "AI    4500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Found 7200 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n",
      "Found 1799 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-04-18 20:18:34.667412: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 928055296 exceeds 10% of free system memory.\n",
      "2024-04-18 20:18:37.882412: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 464027648 exceeds 10% of free system memory.\n",
      "2024-04-18 20:18:37.882544: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 928055296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/113\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:37\u001b[0m 11s/step - accuracy: 0.4375 - loss: 0.7159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 20:18:40.234773: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 928055296 exceeds 10% of free system memory.\n",
      "2024-04-18 20:18:43.429091: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 464027648 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8189 - loss: 0.8263\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66148, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_ukiyo-e.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 6s/step - accuracy: 0.8199 - loss: 0.8221 - val_accuracy: 0.6615 - val_loss: 0.7512\n",
      "Epoch 2/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9849 - loss: 0.1203\n",
      "Epoch 2: val_accuracy improved from 0.66148 to 0.69594, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_ukiyo-e.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 6s/step - accuracy: 0.9848 - loss: 0.1204 - val_accuracy: 0.6959 - val_loss: 0.7315\n",
      "Epoch 3/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9947 - loss: 0.0848\n",
      "Epoch 3: val_accuracy improved from 0.69594 to 0.84825, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_ukiyo-e.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 6s/step - accuracy: 0.9947 - loss: 0.0848 - val_accuracy: 0.8482 - val_loss: 0.4678\n",
      "Epoch 4/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9966 - loss: 0.0535\n",
      "Epoch 4: val_accuracy did not improve from 0.84825\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 6s/step - accuracy: 0.9966 - loss: 0.0535 - val_accuracy: 0.7071 - val_loss: 0.8263\n",
      "Epoch 5/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9967 - loss: 0.0462\n",
      "Epoch 5: val_accuracy did not improve from 0.84825\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 6s/step - accuracy: 0.9967 - loss: 0.0462 - val_accuracy: 0.5164 - val_loss: 3.9032\n",
      "Epoch 6/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9895 - loss: 0.0517\n",
      "Epoch 6: val_accuracy did not improve from 0.84825\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 6s/step - accuracy: 0.9895 - loss: 0.0517 - val_accuracy: 0.5481 - val_loss: 2.8847\n",
      "Epoch 7/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9962 - loss: 0.0279\n",
      "Epoch 7: val_accuracy did not improve from 0.84825\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 6s/step - accuracy: 0.9962 - loss: 0.0279 - val_accuracy: 0.7554 - val_loss: 0.8773\n",
      "Epoch 8/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9995 - loss: 0.0147\n",
      "Epoch 8: val_accuracy did not improve from 0.84825\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 6s/step - accuracy: 0.9995 - loss: 0.0147 - val_accuracy: 0.7204 - val_loss: 1.6128\n",
      "Total training time so far: 5647.85 seconds\n"
     ]
    }
   ],
   "source": [
    "#ukiyo_history = CNN_train_artstyle('ukiyo-e', sample_size=4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_history/ukiyoe_history.json\n"
     ]
    }
   ],
   "source": [
    "#save_training_history(ukiyo_history.history, 'ukiyoe_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/realism\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_realism\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_realism\n",
      "\n",
      "LABEL COUNTS ON realism TRAINING SET\n",
      "label\n",
      "HU    4500\n",
      "AI    4500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Found 7200 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-04-18 21:55:56.529170: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:27: Filling up shuffle buffer (this may take a while): 5 of 8\n",
      "2024-04-18 21:56:09.119440: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7046 - loss: 0.7914\n",
      "Epoch 1: val_accuracy improved from -inf to 0.81500, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_realism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 6s/step - accuracy: 0.7054 - loss: 0.7891 - val_accuracy: 0.8150 - val_loss: 0.3703\n",
      "Epoch 2/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8648 - loss: 0.3476\n",
      "Epoch 2: val_accuracy improved from 0.81500 to 0.88222, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_realism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 6s/step - accuracy: 0.8649 - loss: 0.3473 - val_accuracy: 0.8822 - val_loss: 0.2705\n",
      "Epoch 3/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9145 - loss: 0.2324\n",
      "Epoch 3: val_accuracy improved from 0.88222 to 0.91444, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_realism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 6s/step - accuracy: 0.9145 - loss: 0.2322 - val_accuracy: 0.9144 - val_loss: 0.2225\n",
      "Epoch 4/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9359 - loss: 0.1667\n",
      "Epoch 4: val_accuracy did not improve from 0.91444\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 6s/step - accuracy: 0.9359 - loss: 0.1667 - val_accuracy: 0.8778 - val_loss: 0.3488\n",
      "Epoch 5/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9528 - loss: 0.1169\n",
      "Epoch 5: val_accuracy improved from 0.91444 to 0.92167, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_realism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m696s\u001b[0m 6s/step - accuracy: 0.9528 - loss: 0.1167 - val_accuracy: 0.9217 - val_loss: 0.2035\n",
      "Epoch 6/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9815 - loss: 0.0559\n",
      "Epoch 6: val_accuracy improved from 0.92167 to 0.93556, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_realism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 6s/step - accuracy: 0.9815 - loss: 0.0559 - val_accuracy: 0.9356 - val_loss: 0.1780\n",
      "Epoch 7/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9682 - loss: 0.0924\n",
      "Epoch 7: val_accuracy did not improve from 0.93556\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 6s/step - accuracy: 0.9683 - loss: 0.0921 - val_accuracy: 0.9239 - val_loss: 0.2090\n",
      "Epoch 8/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9886 - loss: 0.0318\n",
      "Epoch 8: val_accuracy did not improve from 0.93556\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 6s/step - accuracy: 0.9886 - loss: 0.0318 - val_accuracy: 0.9067 - val_loss: 0.2916\n",
      "Epoch 9/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9777 - loss: 0.0664\n",
      "Epoch 9: val_accuracy did not improve from 0.93556\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 6s/step - accuracy: 0.9778 - loss: 0.0662 - val_accuracy: 0.9072 - val_loss: 0.2618\n",
      "Epoch 10/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9873 - loss: 0.0370\n",
      "Epoch 10: val_accuracy did not improve from 0.93556\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 6s/step - accuracy: 0.9873 - loss: 0.0370 - val_accuracy: 0.9189 - val_loss: 0.2496\n",
      "Epoch 11/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9947 - loss: 0.0171\n",
      "Epoch 11: val_accuracy did not improve from 0.93556\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m730s\u001b[0m 6s/step - accuracy: 0.9947 - loss: 0.0171 - val_accuracy: 0.9072 - val_loss: 0.2849\n",
      "Total training time so far: 7680.91 seconds\n"
     ]
    }
   ],
   "source": [
    "#realism_history = CNN_train_artstyle('realism', sample_size=4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_history/realism_history.json\n"
     ]
    }
   ],
   "source": [
    "#save_training_history(realism_history.history, 'realism_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baroque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/baroque\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_baroque\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_baroque\n",
      "\n",
      "LABEL COUNTS ON baroque TRAINING SET\n",
      "label\n",
      "HU    4500\n",
      "AI    4500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Found 7200 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-04-19 01:08:59.085354: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 928055296 exceeds 10% of free system memory.\n",
      "2024-04-19 01:09:03.587112: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 464027648 exceeds 10% of free system memory.\n",
      "2024-04-19 01:09:03.587208: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 928055296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/113\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:26\u001b[0m 20s/step - accuracy: 0.4375 - loss: 0.6998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 01:09:08.840357: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 928055296 exceeds 10% of free system memory.\n",
      "2024-04-19 01:09:12.609238: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 464027648 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7660 - loss: 0.6260\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79167, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_baroque.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 6s/step - accuracy: 0.7671 - loss: 0.6229 - val_accuracy: 0.7917 - val_loss: 0.4503\n",
      "Epoch 2/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9724 - loss: 0.0899\n",
      "Epoch 2: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 6s/step - accuracy: 0.9724 - loss: 0.0898 - val_accuracy: 0.5183 - val_loss: 1.0017\n",
      "Epoch 3/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9883 - loss: 0.0481\n",
      "Epoch 3: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 6s/step - accuracy: 0.9883 - loss: 0.0480 - val_accuracy: 0.5372 - val_loss: 2.0935\n",
      "Epoch 4/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9963 - loss: 0.0160\n",
      "Epoch 4: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 6s/step - accuracy: 0.9963 - loss: 0.0160 - val_accuracy: 0.5150 - val_loss: 2.4983\n",
      "Epoch 5/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9958 - loss: 0.0148\n",
      "Epoch 5: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 6s/step - accuracy: 0.9958 - loss: 0.0148 - val_accuracy: 0.7078 - val_loss: 1.1396\n",
      "Epoch 6/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9980 - loss: 0.0107\n",
      "Epoch 6: val_accuracy did not improve from 0.79167\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 6s/step - accuracy: 0.9979 - loss: 0.0107 - val_accuracy: 0.6989 - val_loss: 0.9753\n",
      "Total training time so far: 4192.66 seconds\n",
      "Training history saved to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_history/baroque_history.json\n"
     ]
    }
   ],
   "source": [
    "baroque_history = CNN_train_artstyle('baroque', sample_size=4500)\n",
    "save_training_history(baroque_history.history, 'baroque_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/expressionism\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_expressionism\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_expressionism\n",
      "\n",
      "LABEL COUNTS ON expressionism TRAINING SET\n",
      "label\n",
      "HU    4500\n",
      "AI    4500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Found 7200 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-04-19 02:18:59.032458: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:23: Filling up shuffle buffer (this may take a while): 7 of 8\n",
      "2024-04-19 02:19:00.183223: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9030 - loss: 0.3833\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98056, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_expressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 7s/step - accuracy: 0.9036 - loss: 0.3810 - val_accuracy: 0.9806 - val_loss: 0.0831\n",
      "Epoch 2/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9913 - loss: 0.0330\n",
      "Epoch 2: val_accuracy improved from 0.98056 to 0.99667, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_expressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 7s/step - accuracy: 0.9914 - loss: 0.0329 - val_accuracy: 0.9967 - val_loss: 0.0139\n",
      "Epoch 3/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9987 - loss: 0.0062\n",
      "Epoch 3: val_accuracy did not improve from 0.99667\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 6s/step - accuracy: 0.9987 - loss: 0.0062 - val_accuracy: 0.9967 - val_loss: 0.0127\n",
      "Epoch 4/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9996 - loss: 0.0018\n",
      "Epoch 4: val_accuracy improved from 0.99667 to 0.99722, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_expressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 6s/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9972 - val_loss: 0.0090\n",
      "Epoch 5/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9962 - loss: 0.0119\n",
      "Epoch 5: val_accuracy did not improve from 0.99722\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 6s/step - accuracy: 0.9962 - loss: 0.0120 - val_accuracy: 0.9744 - val_loss: 0.1259\n",
      "Epoch 6/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9988 - loss: 0.0044\n",
      "Epoch 6: val_accuracy improved from 0.99722 to 0.99778, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_expressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 6s/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9978 - val_loss: 0.0077\n",
      "Epoch 7/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9971 - loss: 0.0067\n",
      "Epoch 7: val_accuracy improved from 0.99778 to 0.99889, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_expressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m745s\u001b[0m 6s/step - accuracy: 0.9972 - loss: 0.0066 - val_accuracy: 0.9989 - val_loss: 0.0040\n",
      "Epoch 8/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 8.4468e-04\n",
      "Epoch 8: val_accuracy did not improve from 0.99889\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 8.4203e-04 - val_accuracy: 0.9939 - val_loss: 0.0265\n",
      "Epoch 9/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 8.7337e-05\n",
      "Epoch 9: val_accuracy did not improve from 0.99889\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m692s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 8.8164e-05 - val_accuracy: 0.9961 - val_loss: 0.0201\n",
      "Epoch 10/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 2.7068e-04\n",
      "Epoch 10: val_accuracy did not improve from 0.99889\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 2.7309e-04 - val_accuracy: 0.9978 - val_loss: 0.0095\n",
      "Epoch 11/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 6.2275e-04\n",
      "Epoch 11: val_accuracy did not improve from 0.99889\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 6.2073e-04 - val_accuracy: 0.9978 - val_loss: 0.0111\n",
      "Epoch 12/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9997 - loss: 3.7212e-04\n",
      "Epoch 12: val_accuracy did not improve from 0.99889\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 6s/step - accuracy: 0.9997 - loss: 3.7093e-04 - val_accuracy: 0.9933 - val_loss: 0.0186\n",
      "Total training time so far: 8555.46 seconds\n",
      "Training history saved to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_history/expressionism_history.json\n"
     ]
    }
   ],
   "source": [
    "expressionism_history = CNN_train_artstyle('expressionism', sample_size=4500)\n",
    "save_training_history(expressionism_history.history, 'expressionism_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/impressionism\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_impressionism\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_impressionism\n",
      "\n",
      "LABEL COUNTS ON impressionism TRAINING SET\n",
      "label\n",
      "HU    4500\n",
      "AI    4500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Found 7200 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8896 - loss: 0.4874\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99222, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_impressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m705s\u001b[0m 6s/step - accuracy: 0.8903 - loss: 0.4846 - val_accuracy: 0.9922 - val_loss: 0.0265\n",
      "Epoch 2/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9923 - loss: 0.0308\n",
      "Epoch 2: val_accuracy did not improve from 0.99222\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m677s\u001b[0m 6s/step - accuracy: 0.9923 - loss: 0.0308 - val_accuracy: 0.9922 - val_loss: 0.0314\n",
      "Epoch 3/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9941 - loss: 0.0260\n",
      "Epoch 3: val_accuracy improved from 0.99222 to 0.99444, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_impressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 6s/step - accuracy: 0.9941 - loss: 0.0259 - val_accuracy: 0.9944 - val_loss: 0.0205\n",
      "Epoch 4/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9951 - loss: 0.0157\n",
      "Epoch 4: val_accuracy did not improve from 0.99444\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 6s/step - accuracy: 0.9951 - loss: 0.0158 - val_accuracy: 0.9628 - val_loss: 0.1136\n",
      "Epoch 5/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9965 - loss: 0.0140\n",
      "Epoch 5: val_accuracy did not improve from 0.99444\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 6s/step - accuracy: 0.9965 - loss: 0.0140 - val_accuracy: 0.9944 - val_loss: 0.0248\n",
      "Epoch 6/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9985 - loss: 0.0047\n",
      "Epoch 6: val_accuracy did not improve from 0.99444\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 6s/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9206 - val_loss: 0.2343\n",
      "Epoch 7/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9964 - loss: 0.0138\n",
      "Epoch 7: val_accuracy did not improve from 0.99444\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 6s/step - accuracy: 0.9964 - loss: 0.0138 - val_accuracy: 0.9878 - val_loss: 0.0474\n",
      "Epoch 8/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9992 - loss: 0.0033\n",
      "Epoch 8: val_accuracy did not improve from 0.99444\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 6s/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9939 - val_loss: 0.0235\n",
      "Total training time so far: 5422.52 seconds\n",
      "Training history saved to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_history/impressionism_history.json\n"
     ]
    }
   ],
   "source": [
    "impressionism_history = CNN_train_artstyle('impressionism', sample_size=4500)\n",
    "save_training_history(impressionism_history.history, 'impressionism_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Impressionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location of human samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/post_impressionism\n",
      "Location of ai_sd samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_post_impressionism\n",
      "Location of ai_ld samples: /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/train/AI_SD_post_impressionism\n",
      "\n",
      "LABEL COUNTS ON post_impressionism TRAINING SET\n",
      "label\n",
      "HU    4500\n",
      "AI    4500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Found 7200 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n",
      "Found 1800 validated image filenames belonging to 2 classes.\n",
      "{'AI': 0, 'HU': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g0dbot/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-04-19 06:12:54.740037: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:81: Filling up shuffle buffer (this may take a while): 7 of 8\n",
      "2024-04-19 06:12:56.534432: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8995 - loss: 0.5325\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94500, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_post_impressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 6s/step - accuracy: 0.9001 - loss: 0.5293 - val_accuracy: 0.9450 - val_loss: 0.1368\n",
      "Epoch 2/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9954 - loss: 0.0153\n",
      "Epoch 2: val_accuracy improved from 0.94500 to 0.95056, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_post_impressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m750s\u001b[0m 7s/step - accuracy: 0.9954 - loss: 0.0153 - val_accuracy: 0.9506 - val_loss: 0.1781\n",
      "Epoch 3/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9791 - loss: 0.0766\n",
      "Epoch 3: val_accuracy improved from 0.95056 to 0.99333, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_post_impressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 6s/step - accuracy: 0.9792 - loss: 0.0763 - val_accuracy: 0.9933 - val_loss: 0.0219\n",
      "Epoch 4/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9968 - loss: 0.0120\n",
      "Epoch 4: val_accuracy did not improve from 0.99333\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 6s/step - accuracy: 0.9968 - loss: 0.0120 - val_accuracy: 0.9889 - val_loss: 0.0362\n",
      "Epoch 5/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9976 - loss: 0.0061\n",
      "Epoch 5: val_accuracy improved from 0.99333 to 0.99778, saving model to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_checkpoints/CNN_post_impressionism.keras\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 6s/step - accuracy: 0.9976 - loss: 0.0061 - val_accuracy: 0.9978 - val_loss: 0.0085\n",
      "Epoch 6/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9959 - loss: 0.0119\n",
      "Epoch 6: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 6s/step - accuracy: 0.9959 - loss: 0.0119 - val_accuracy: 0.9933 - val_loss: 0.0240\n",
      "Epoch 7/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9995 - loss: 0.0017\n",
      "Epoch 7: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 6s/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9972 - val_loss: 0.0097\n",
      "Epoch 8/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9974 - loss: 0.0051\n",
      "Epoch 8: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 6s/step - accuracy: 0.9974 - loss: 0.0051 - val_accuracy: 0.9956 - val_loss: 0.0253\n",
      "Epoch 9/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9996 - loss: 8.2990e-04\n",
      "Epoch 9: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 6s/step - accuracy: 0.9996 - loss: 8.2803e-04 - val_accuracy: 0.9922 - val_loss: 0.0478\n",
      "Epoch 10/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9995 - loss: 0.0015\n",
      "Epoch 10: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 6s/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9978 - val_loss: 0.0062\n",
      "Epoch 11/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9983 - loss: 0.0063\n",
      "Epoch 11: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 6s/step - accuracy: 0.9983 - loss: 0.0062 - val_accuracy: 0.9950 - val_loss: 0.0152\n",
      "Epoch 12/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9998 - loss: 7.8309e-04\n",
      "Epoch 12: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 6s/step - accuracy: 0.9998 - loss: 7.8161e-04 - val_accuracy: 0.9956 - val_loss: 0.0105\n",
      "Epoch 13/13\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9988 - loss: 0.0019\n",
      "Epoch 13: val_accuracy did not improve from 0.99778\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 6s/step - accuracy: 0.9988 - loss: 0.0020 - val_accuracy: 0.9961 - val_loss: 0.0326\n",
      "Total training time so far: 8610.38 seconds\n",
      "Training history saved to /home/g0dbot/Desktop/COMP3610/proj/archive/Real_AI_SD_LD_Dataset/models_history/post_impressionism_history.json\n"
     ]
    }
   ],
   "source": [
    "post_impressionism_history = CNN_train_artstyle('post_impressionism', sample_size=4500)\n",
    "save_training_history(post_impressionism_history.history, 'post_impressionism_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaissance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaissance_history = CNN_train_artstyle('renaissance', sample_size=4500)\n",
    "#save_training_history(renaissance_history.history, 'renaissance_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Romanticism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#romanticism_history = CNN_train_artstyle('romanticism', sample_size=4500)\n",
    "#save_training_history(romanticism_history.history, 'romanticism_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surrealism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#surrealism_history = CNN_train_artstyle('surrealism', sample_size=4500)\n",
    "#save_training_history(surrealism_history.history, 'surrealism_history.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Art Nouveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#art_nouveau_history = CNN_train_artstyle('art_nouveau', sample_size=4500)\n",
    "#save_training_history(art_nouveau_history.history, 'art_nouveau_history.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
